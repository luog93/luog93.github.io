---
title: Affective Brain-Comouter Interactions
summary: Multimodal emotion recognition using EEG and eye movements.
tags:
  - Deep Learning
date: '2023-01-01T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: Photo
  focal_point: Smart

links:
  - icon: twitter
    icon_pack: fab
    name: Follow
    url: https://twitter.com/#
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
slides: ""
---

Brain-computer interfaces (BCIs) are usually defined as a direct means of communication between the brain and external devices or systems which enable the brain signal to control some external activity. BCIs also allow investigation of brain activity and analysis of brain state. Affective Brain-Computer Interfaces (aBCIs) can be defined as systems that estimate human affect from brain signals. 

The interest in automatic detection of people's affective states has increased over the last few decades. Studies have shown that affective states play an important role in human decision making. The ability to manage one's affective states is also related to the abilities of logical reasoning, learning and extracting important information. According to Goleman's model of emotional intelligence, having knowledge of your own affective states is a key factor behind personal and professional success.

